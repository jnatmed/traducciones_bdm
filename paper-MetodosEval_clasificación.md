[Paper - Métodos de evaluación de la clasificación](https://www.emerald.com/insight/content/doi/10.1016/j.aci.2018.08.003/full/pdf?title=classification-assessment-methods)

Resumen. Las técnicas de clasificación se han aplicado a muchas aplicaciones en varios campos de las ciencias. Hay varias formas de evaluar los algoritmos de clasificación. El análisis de tales métricas y su significado debe interpretarse correctamente para evaluar diferentes algoritmos de aprendizaje. La mayoría de estas medidas son métricas escalares y algunas de ellas son métodos gráficos. Este documento presenta una descripción detallada de las medidas de evaluación de clasificación con el objetivo de proporcionar los conceptos básicos de estas medidas y mostrar cómo funciona para servir como una fuente integral para los investigadores interesados ​​en este campo. Esta descripción general comienza destacando la definición de la matriz de confusión en problemas de clasificación binaria y multiclase. Muchas medidas de clasificación también se explican en detalle, y se presenta la influencia de los datos equilibrados y desequilibrados en cada métrica. Se presenta un ejemplo ilustrativo para mostrar (1) cómo calcular estas medidas en problemas de clasificación binaria y multiclase, y (2) la solidez de algunas medidas frente a datos equilibrados y desequilibrados. Además, se presentan con detalles algunas medidas gráficas, como las características operativas del receptor (ROC), la recuperación de precisión y las curvas de compensación de error de detección (DET). Además, en un enfoque paso a paso, se muestran diferentes ejemplos numéricos para explicar los pasos de preprocesamiento para trazar curvas ROC, PR y DET. 

Palabras clave Características operativas del receptor (ROC), Matriz de confusión, Curva de precisión-recuperación (PR), Clasificación, Métodos de evaluación.

1. Introducción Las técnicas de clasificación se han aplicado a muchas aplicaciones en varios campos de las ciencias. En los modelos de clasificación, los datos de entrenamiento se usan para construir un modelo de clasificación para predecir la etiqueta de clase para una nueva muestra. Los resultados de los modelos de clasificación pueden ser discretos como en el clasificador de árboles de decisión o continuos como el clasificador Naive Bayes [7]. Sin embargo, los resultados de los algoritmos de aprendizaje deben evaluarse y analizarse cuidadosamente, y este análisis debe interpretarse correctamente, para evaluar diferentes algoritmos de aprendizaje. El rendimiento de clasificación está representado por valores escalares como en diferentes métricas como precisión, sensibilidad y especificidad. Comparar diferentes clasificadores utilizando estas medidas es fácil, pero tiene muchos problemas, como la sensibilidad a los datos desequilibrados y el hecho de ignorar el rendimiento de algunas clases. Los métodos de evaluación gráfica, como las características operativas del receptor (ROC) y las curvas de recuperación de precisión, brindan diferentes interpretaciones del rendimiento de la clasificación.

Algunas de las medidas que se derivan de la matriz de confusión para evaluar una prueba de diagnóstico se informan en [19]. En ese documento, solo se introdujeron ocho medidas. Powers presentó una excelente discusión sobre los métodos de evaluación de precisión, recuperación, puntuación F, ROC, información, marcado y correlación con explicaciones detalladas [16]. Sokolova et al. informó algunas métricas que se utilizan en el diagnóstico médico [20]. Además, en [21] se presenta una buena investigación de algunas medidas y la solidez de estas medidas frente a diferentes cambios en la matriz de confusión. Tom Fawcett presentó una introducción detallada a la curva ROC que incluye (1) buenas explicaciones de los conceptos básicos de la curva ROC, (2) un ejemplo claro para generar la curva ROC, (3) debates completos y (4) buenas explicaciones del Área métrica bajo la curva (AUC) [8]. Jesse Davis y Mark Goadrich informaron sobre la relación entre las curvas ROC y Precision-Recall [5]. Nuestro documento presenta una descripción detallada de los métodos de evaluación de la clasificación con el objetivo de proporcionar los principios básicos de estas medidas y mostrar cómo funciona para servir como una fuente integral para los investigadores interesados ​​en este campo. Este documento tiene detalles de la mayoría de los métodos de evaluación de clasificación conocidos. Además, este documento presenta (1) las relaciones entre los diferentes métodos de evaluación, (2) ejemplos numéricos para mostrar cómo calcular estos métodos de evaluación, (3) la solidez de cada método frente a datos desequilibrados, que es uno de los problemas más importantes en la realidad. -aplicaciones de tiempo, y (4) explicaciones de diferentes curvas en un enfoque paso a paso. Este documento está dividido en ocho secciones. La sección 2 ofrece una descripción general de los métodos de evaluación de la clasificación. Esta sección comienza explicando la matriz de confusión para problemas de clasificación binaria y multiclase. Según los datos que se pueden extraer de la matriz de confusión, se pueden calcular muchas métricas de clasificación. Además, se introduce la influencia de los datos equilibrados y desequilibrados en cada método de evaluación. Además, se presenta un ejemplo numérico ilustrativo para mostrar (1) cómo calcular estas medidas en problemas de clasificación binarios y de clases múltiples, y (2) la solidez de algunas medidas frente a datos equilibrados y desequilibrados. La Sección 3 presenta los conceptos básicos de la curva ROC, que son necesarios para comprender cómo trazarla e interpretarla. Esta sección también presenta pasos visualizados con un ejemplo ilustrativo para trazar la curva ROC. La medida AUC se presenta en la Sección 4. En esta sección, se explica el algoritmo AUC con pasos detallados. La Sección 5 presenta los conceptos básicos de la curva Precision-Recall y cómo interpretarla. Además, en un enfoque paso a paso, se muestran diferentes ejemplos numéricos para explicar los pasos de preprocesamiento para trazar las curvas ROC y PR en las Secciones 3 y 5. Los métodos de evaluación de clasificación para modelos biométricos, incluidos los pasos para trazar la curva DET, se presentan en la Sección 6. En la Sección 7, se presentan los resultados en términos de diferentes métodos de evaluación de un experimento simple. Finalmente, las observaciones finales se darán en la Sección 8.

2. Rendimiento de la clasificación El método de evaluación es un factor clave para evaluar el rendimiento de la clasificación y guiar el modelado del clasificador. Hay tres fases principales del proceso de clasificación, a saber, fase de entrenamiento, fase de validación y fase de prueba. El modelo se entrena utilizando patrones de entrada y esta fase se denomina fase de entrenamiento. Estos patrones de entrada se denominan datos de entrenamiento que se utilizan para entrenar el modelo. Durante esta fase, se ajustan los parámetros de un modelo de clasificación. El error de entrenamiento mide qué tan bien se ajusta el modelo entrenado a los datos de entrenamiento. Sin embargo, el error de entrenamiento siempre es menor que el error de prueba y el error de validación porque el modelo entrenado se ajusta a los mismos datos que se utilizan en la fase de entrenamiento. El objetivo de un algoritmo de aprendizaje es aprender de los datos de entrenamiento para predecir etiquetas de clase para datos no vistos; esto está en la fase de prueba. Sin embargo, el error de prueba o el error fuera de muestra no se puede estimar porque se desconocen las etiquetas de clase o los resultados de las muestras de prueba. Esta es la razón por la cual la fase de validación se utiliza para evaluar el desempeño del modelo entrenado. En la fase de validación, los datos de validación proporcionan una evaluación imparcial del modelo entrenado mientras ajustan los hiperparámetros del modelo. Según el número de clases, existen dos tipos de problemas de clasificación, a saber, la clasificación binaria donde solo hay dos clases y la clasificación multiclase donde el número de clases es superior a dos. Supongamos que tenemos dos clases, es decir, clasificación binaria, P para clase positiva y N para clase negativa. Una muestra desconocida se clasifica en P o N. El modelo de clasificación que se entrenó en la fase de entrenamiento se usa para predecir las verdaderas clases de muestras desconocidas. Este modelo de clasificación produce salidas continuas o discretas. La salida discreta que se genera a partir de un modelo de clasificación representa la etiqueta de clase discreta pronosticada de la muestra de prueba/desconocida, mientras que la salida continua representa la estimación de la probabilidad de pertenencia a la clase de la muestra. La Figura 1 muestra que hay cuatro salidas posibles que representan los elementos de una matriz de confusión 2 3 2 o una tabla de contingencia. La diagonal verde representa predicciones correctas y la diagonal rosa indica predicciones incorrectas. Si la muestra es positiva y se clasifica como positiva, es decir, muestra positiva clasificada correctamente, se cuenta como un verdadero positivo (VP); si se clasifica como negativo, se considera como un falso negativo (FN) o error tipo II. Si la muestra es negativa y se clasifica como negativa se considera verdadero negativo (NT); si se clasifica como positivo, se contabiliza como falso positivo (FP), falsa alarma o error tipo I. Como presentaremos en las próximas secciones, la matriz de confusión se utiliza para calcular muchas métricas de clasificación comunes. La figura 2 muestra la matriz de confusión para un problema de clasificación multiclase con tres clases (A, B y C). Como se muestra, TPA es la cantidad de muestras positivas verdaderas en la clase A, es decir, la cantidad de muestras que se clasificaron correctamente de la clase A, y EAB son las muestras de la clase A que se clasificaron incorrectamente como clase B, es decir, muestras mal clasificadas. Por lo tanto, el falso negativo en la clase A (FNA) es la suma de EAB y EAC (FNA ¼ EAB þ EAC) que indica la suma de todas las muestras de clase A que se clasificaron incorrectamente como clase B o C. Simplemente, FN de cualquier La clase que se encuentra en una columna se puede calcular sumando los errores en esa clase/columna. Mientras que el falso positivo para cualquier clase predicha que se encuentra en una fila representa la suma de todos los errores en esa fila. Por ejemplo, el falso positivo en la clase A (FPA) se calcula de la siguiente manera, FPA ¼ EBA þ ECA. Con m 3 m matriz de confusión hay m clasificaciones correctas y m2 − m posibles errores [22].

2.1 Métricas de clasificación con datos desequilibrados Los diferentes métodos de evaluación son sensibles a los datos desequilibrados cuando las muestras de una clase en un conjunto de datos superan en número a las muestras de la(s) otra(s) clase(s) [25]. Para explicar esto, considere la matriz de confusión en la Figura 1. La distribución de clase es la relación entre las muestras positivas y negativas (PN) representa la relación entre la columna de la izquierda y la columna de la derecha. Cualquier métrica de evaluación que use valores de ambas columnas será sensible a los datos desequilibrados como se informa en [8]. Por ejemplo, algunas métricas como la exactitud y la precisión1 usan valores de ambas columnas de la matriz de confusión; por lo tanto, a medida que cambien las distribuciones de datos, estas métricas también cambiarán, incluso si el rendimiento del clasificador no lo hace. Por lo tanto, estas métricas no pueden distinguir entre el número de etiquetas corregidas de diferentes clases [11]. Este hecho es parcialmente cierto porque hay algunas métricas como la media geométrica (GM) y el índice de Youden (YI) 2 que usan valores de ambas columnas y estas métricas se pueden usar con datos equilibrados y desequilibrados. Esto se puede interpretar como que las métricas que usan valores de una columna cancelan los cambios en la distribución de clases. Sin embargo, algunas métricas que usan valores de ambas columnas no son sensibles a los datos desequilibrados porque los cambios en la distribución de clases se cancelan entre sí. Por ejemplo, la precisión se define de la siguiente manera, [fórmula] y el GM se define de la siguiente manera, GM ¼ [fórmula] [fórmula]; por lo tanto, ambas métricas usan valores de ambas columnas de la matriz de confusión. Se puede cambiar la distribución de clases aumentando/disminuyendo el número de muestras de clase negativa/positiva. Con el mismo rendimiento de clasificación, suponga que las muestras de clase negativa aumentan α veces; así, los valores de TN y FP serán αTN y αFP, respectivamente; por lo tanto, la precisión será, Acc [fórmulas]. Esto significa que la precisión se ve afectada por los cambios en la distribución de clases. Por otro lado, la métrica de GM será [fórmulas] y, por lo tanto, los cambios en la clase negativa se cancelan entre sí. Esta es la razón por la que la métrica GM es adecuada para los datos desequilibrados. De manera similar, se puede verificar cualquier métrica para saber si es sensible a los datos desequilibrados o no.

2.2 Precisión y tasa de error La precisión (Acc) es una de las medidas más comúnmente utilizadas para el desempeño de la clasificación, y se define como una relación entre las muestras correctamente clasificadas y el número total de muestras de la siguiente manera [20]:

$ Acc = \frac{TP + TN}{TP + TN + FP + FN}$ (1)


$ GM = \sqrt{TPR x TNR} = \sqrt{\frac{TP}{TP+FN} x \frac{}{}}$ (1)

donde P y N indican el número de muestras positivas y negativas, respectivamente. El complemento de la métrica de precisión es la tasa de error (ERR) o tasa de clasificación errónea. Esta métrica representa el número de muestras mal clasificadas de las clases positivas y negativas, y se calcula de la siguiente manera, EER ¼ 1−Acc ¼ ðFP þ FNÞ=ðTP þ TN þ FP þ FNÞ [4]. Tanto las métricas de precisión como las de tasa de error son sensibles a los datos desequilibrados. Otro problema con la precisión es que dos clasificadores pueden producir la misma precisión pero funcionar de manera diferente con respecto a los tipos de decisiones correctas e incorrectas que proporcionan [9]. Sin embargo, Takaya Saito y Marc Rehmsmeier informaron que la precisión es adecuada con datos desequilibrados porque descubrieron que los valores de precisión de los datos equilibrados y desequilibrados en su ejemplo eran idénticos [17]. La razón por la que los valores de precisión eran idénticos en su ejemplo es que la suma de TP y TN en los datos equilibrados y desequilibrados era la misma.

#### 2.3 Sensibilidad y especificidad 

La sensibilidad, la tasa de verdaderos positivos (TPR), la tasa de aciertos o la recuperación de un clasificador representa las muestras positivas correctamente clasificadas con respecto al número total de muestras positivas, y se estima de acuerdo con la ecuación. (2) [20]. Mientras que la especificidad, la tasa de verdaderos negativos (TNR) o el recuerdo inverso se expresan como la relación entre las muestras negativas correctamente clasificadas y el número total de muestras negativas, como en la ecuación. (2) [20]. Así, la especificidad representa la proporción de muestras negativas que se clasificaron correctamente y la sensibilidad es la proporción de muestras positivas que se clasificaron correctamente. En general, podemos considerar la sensibilidad y la especificidad como dos tipos de precisión, donde la primera para muestras positivas reales y la segunda para muestras negativas reales. La sensibilidad depende de TP y FN que están en la misma columna de la matriz de confusión, y de manera similar, la métrica de especificidad depende de TN y FP que están en la misma columna; por lo tanto, tanto la sensibilidad como la especificidad se pueden utilizar para evaluar el rendimiento de la clasificación con datos desequilibrados [9].

La precisión también se puede definir en términos de sensibilidad y especificidad de la siguiente manera [20]:

## 2.4 Tasas de falsos positivos y falsos negativos 
La tasa de falsos positivos (FPR) también se denomina tasa de falsas alarmas (FAR) o Fallout, y representa la relación entre las muestras negativas clasificadas incorrectamente y el número total de muestras negativas [16]. En otras palabras, es la proporción de las muestras negativas que se clasificaron incorrectamente. Por lo tanto, complementa la especificidad como en Eq. (4) [21]. La tasa de falsos negativos (FNR) o tasa de fallas es la proporción de muestras positivas que se clasificaron incorrectamente. Por lo tanto, complementa la medida de sensibilidad y se define en la ecuación. (5). Tanto FPR como FNR no son sensibles a los cambios en las distribuciones de datos y, por lo tanto, ambas métricas se pueden usar con datos desequilibrados [9].

## 2.5 Valores predictivos 
Los valores predictivos (positivos y negativos) reflejan el rendimiento de la predicción. El valor de predicción positivo (PPV) o precisión representa la proporción de muestras positivas que se clasificaron correctamente con respecto al número total de muestras positivas previstas, como se indica en la ecuación. (6) [20]. Por el contrario, el valor predictivo negativo (NPV), la precisión inversa o la precisión negativa verdadera (TNA) mide la proporción de muestras negativas que se $\frac{\sqrt{2*3}}{\sqrt{2x3}}$ clasificaron correctamente en el total.
