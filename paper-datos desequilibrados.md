### Aprendiendo de datos desequilibrados

Resumen—Con la expansión continua de la disponibilidad de datos en muchos sistemas en red, complejos y a gran escala, como vigilancia, seguridad, Internet y finanzas, se vuelve fundamental avanzar en la comprensión fundamental del descubrimiento y análisis de conocimiento a partir de datos sin procesar para respaldar procesos de toma de decisiones. Aunque las técnicas existentes de descubrimiento de conocimiento e ingeniería de datos han mostrado un gran éxito en muchas aplicaciones del mundo real, el problema de aprender de datos desequilibrados (el problema del aprendizaje desequilibrado) es un desafío relativamente nuevo que ha atraído una atención creciente tanto de la academia como de la industria. El problema del aprendizaje desequilibrado se relaciona con el rendimiento de los algoritmos de aprendizaje en presencia de datos subrepresentados y sesgos severos en la distribución de clases. Debido a las complejas características inherentes de los conjuntos de datos desequilibrados, aprender de dichos datos requiere nuevos conocimientos, principios, algoritmos y herramientas para transformar grandes cantidades de datos sin procesar de manera eficiente en información y representación del conocimiento. En este documento, proporcionamos una revisión exhaustiva del desarrollo de la investigación en el aprendizaje a partir de datos desequilibrados. Nuestro enfoque es proporcionar una revisión crítica de la naturaleza del problema, las tecnologías de punta y las métricas de evaluación actuales utilizadas para evaluar el rendimiento del aprendizaje en el escenario de aprendizaje desequilibrado. Además, con el fin de estimular la investigación futura en este campo, también destacamos las principales oportunidades y desafíos, así como las posibles direcciones de investigación importantes para aprender de los datos desequilibrados.

Los desarrollos RECIENTES en ciencia y tecnología han permitido que el crecimiento y la disponibilidad de datos sin procesar se produzcan a un ritmo explosivo. Esto ha creado una inmensa oportunidad para que el descubrimiento de conocimiento y la investigación de ingeniería de datos desempeñen un papel esencial en una amplia gama de aplicaciones, desde la vida civil diaria hasta la seguridad nacional, desde el procesamiento de información empresarial hasta los sistemas gubernamentales de apoyo a la toma de decisiones, desde el análisis de datos a microescala hasta la macroescala. Descubrimiento del conocimiento. En los últimos años, el problema del aprendizaje desequilibrado ha suscitado un gran interés por parte de la academia, la industria y las agencias de financiación gubernamentales. El problema fundamental con el problema del aprendizaje desequilibrado es la capacidad de los datos desequilibrados para comprometer significativamente el rendimiento de la mayoría de los algoritmos de aprendizaje estándar. La mayoría de los algoritmos estándar asumen o esperan distribuciones de clase equilibradas o costos de clasificación errónea iguales. Por lo tanto, cuando se les presentan conjuntos de datos complejos y desequilibrados, estos algoritmos no logran representar adecuadamente las características distributivas de los datos y, en consecuencia, proporcionan precisiones desfavorables en todas las clases de datos. Cuando se traduce a dominios del mundo real, el problema del aprendizaje desequilibrado representa un problema recurrente de gran importancia con implicaciones de amplio alcance, que justifica una exploración cada vez mayor. Este mayor interés se refleja en la reciente entrega de varios talleres, conferencias y ediciones especiales importantes, incluido el taller de la Asociación Estadounidense para la Inteligencia Artificial (ahora la Asociación para el Avance de la Inteligencia Artificial) sobre el aprendizaje de conjuntos de datos desequilibrados (AAAI). '00) [1], el taller de la Conferencia Internacional sobre Aprendizaje Automático sobre Aprendizaje a partir de Conjuntos de Datos Desequilibrados (ICML'03) [2], y el Grupo de Interés Especial de la Asociación de Maquinaria Informática sobre Descubrimiento de Conocimiento y Exploraciones de Minería de Datos ( Exploraciones ACM SIGKDD '04) [3]. Con la gran afluencia de atención dedicada al problema del aprendizaje desequilibrado y la gran actividad de avance en este campo, mantenerse al tanto de todos los desarrollos actuales puede ser una tarea abrumadora. La figura 1 muestra una estimación del número de publicaciones sobre el problema del aprendizaje desequilibrado durante la última década con base en las bases de datos del Instituto de Ingenieros Eléctricos y Electrónicos (IEEE) y la Asociación de Maquinaria de Computación (ACM). Como puede verse, la actividad de publicaciones en este campo está creciendo a un ritmo explosivo. Debido a la edad relativamente joven de este campo y debido a su rápida expansión, las evaluaciones consistentes de los trabajos pasados ​​y actuales en el campo, además de las proyecciones para la investigación futura, son esenciales para el desarrollo a largo plazo. En este documento, buscamos proporcionar una encuesta sobre la comprensión actual del problema del aprendizaje desequilibrado y las soluciones de vanguardia creadas para abordar este problema. Además, con el fin de estimular la investigación futura en este campo, también destacamos las principales oportunidades y desafíos para aprender de datos desequilibrados. En particular, primero describimos la naturaleza del problema del aprendizaje desequilibrado en la Sección 2, que proporciona la base para nuestra revisión de las soluciones de aprendizaje desequilibrado. En la Sección 3, proporcionamos una revisión crítica de los desarrollos de investigación innovadores que se enfocan en el problema del aprendizaje desequilibrado, incluidos los métodos de muestreo, los métodos de aprendizaje sensibles a los costos, los métodos de aprendizaje basados ​​en kernel y los métodos de aprendizaje activo. Las métricas de evaluación para el aprendizaje desequilibrado se revisan en la Sección 4, que proporciona varios métodos sugeridos que se utilizan para comparar y evaluar el desempeño de diferentes algoritmos de aprendizaje desequilibrado. Teniendo en cuenta que el aprendizaje a partir de datos desequilibrados es un tema relativamente nuevo en la comunidad investigadora, en la Sección 5 presentamos una discusión detallada sobre las oportunidades y desafíos para el desarrollo de la investigación en este campo. Esperamos que esta sección proporcione algunas sugerencias útiles para promover y guiar el avance a largo plazo de la investigación en esta área. Finalmente, se proporciona una conclusión en la Sección 6. 

### 2 NATURALEZA DEL PROBLEMA

Técnicamente hablando, cualquier conjunto de datos que muestre una distribución desigual entre sus clases puede considerarse desequilibrado. Sin embargo, el entendimiento común en la comunidad es que los datos desequilibrados corresponden a conjuntos de datos que exhiben desequilibrios significativos y, en algunos casos, extremos. Específicamente, esta forma de desequilibrio se conoce como desequilibrio entre clases; no son infrecuentes entre los desequilibrios de clase del orden de 100:1, 1000:1 y 10 000:1, donde en cada caso, una clase supera con creces a otra [4], [5], [6]. Aunque esta descripción parecería implicar que todos los desequilibrios entre clases son innatamente binarios (o de dos clases), observamos que hay datos multiclase en los que existen desequilibrios entre las distintas clases [7], [8], [9], [10], [11], [12]. En este documento, solo abordamos brevemente el problema de aprendizaje desequilibrado multiclase, centrándonos en cambio en el problema de aprendizaje desequilibrado de dos clases por consideraciones de espacio. Para resaltar las implicaciones del problema del aprendizaje desequilibrado en el mundo real, presentamos un ejemplo de aplicaciones biomédicas. Considere el "Conjunto de datos de mamografía", una colección de imágenes adquiridas de una serie de exámenes de mamografía realizados en un conjunto de pacientes distintos, que se ha utilizado ampliamente en el análisis de algoritmos que abordan el problema del aprendizaje desequilibrado [13], [14 ], [15]. Analizando las imágenes en sentido binario, las clases naturales (etiquetas) que surgen son “Positivo” o “Negativo” para una imagen representativa de un paciente “canceroso” o “sano”, respectivamente. Por experiencia, uno esperaría que el número de pacientes no cancerosos exceda en gran medida el número de pacientes cancerosos; de hecho, este conjunto de datos contiene 10.923 muestras "Negativas" (clase mayoritaria) y 260 muestras "Positivas" (clase minoritaria). Preferiblemente, necesitamos un clasificador que proporcione un grado equilibrado de precisión predictiva (idealmente 100 por ciento) para las clases mayoritaria y minoritaria en el conjunto de datos. En realidad, encontramos que los clasificadores tienden a proporcionar un grado de precisión gravemente desequilibrado, con la clase mayoritaria con una precisión cercana al 100 % y la clase minoritaria con una precisión del 0 al 10 %, por ejemplo [13], [15] . Supongamos que un clasificador logra una precisión del 10 por ciento en la clase minoritaria del conjunto de datos de mamografía. Analíticamente, esto sugeriría que 234 muestras minoritarias están mal clasificadas como muestras mayoritarias. La consecuencia de esto es equivalente a 234 pacientes cancerosos clasificados (diagnosticados) como no cancerosos. En la industria médica, las ramificaciones de tal consecuencia pueden ser abrumadoramente costosas, más que clasificar a un paciente no canceroso como canceroso [16]. Por lo tanto, es evidente que para este dominio necesitamos un clasificador que proporcione una alta precisión para la clase minoritaria sin poner en grave peligro la precisión de la clase mayoritaria. Además, esto también sugiere que la práctica de evaluación convencional de usar criterios de evaluación singulares, como la precisión general o la tasa de error, no proporciona información adecuada en el caso de un aprendizaje desequilibrado. Por lo tanto, se necesitan métricas de evaluación más informativas, como ***las curvas de características operativas del receptor***, las curvas de recuperación de precisión y las curvas de costo, para realizar evaluaciones concluyentes del rendimiento en presencia de datos desequilibrados. Estos temas serán discutidos en detalle en la Sección 4 de este documento. Además de las aplicaciones biomédicas, la especulación adicional arrojará consecuencias similares para dominios como la **detección de fraudes**, **la intrusión en la red** y **la detección de derrames de petróleo**, por nombrar algunos [5], [16], [17], [18], [19]. ].

Los desequilibrios de esta forma se conocen comúnmente como intrínsecos, es decir, el desequilibrio es un resultado directo de la naturaleza del espacio de datos. Sin embargo, los datos desequilibrados no se limitan únicamente a la variedad intrínseca. Factores variables como el tiempo y el almacenamiento también dan lugar a conjuntos de datos desequilibrados. Los desequilibrios de este tipo se consideran extrínsecos, es decir, el desequilibrio no está directamente relacionado con la naturaleza del espacio de datos. Los desequilibrios extrínsecos son tan interesantes como sus contrapartes intrínsecas, ya que es muy posible que el espacio de datos del que se obtiene un conjunto de datos desequilibrados extrínsecos no esté desequilibrado en absoluto. Por ejemplo, supongamos que se obtiene un conjunto de datos de un flujo de datos continuo de datos equilibrados durante un intervalo de tiempo específico, y si durante este intervalo, la transmisión tiene interrupciones esporádicas en las que no se transmiten los datos, entonces es posible que el conjunto de datos adquiridos puede estar desequilibrado, en cuyo caso el conjunto de datos sería un conjunto de datos desequilibrado extrínseco obtenido de un espacio de datos equilibrado. Además del desequilibrio intrínseco y extrínseco, es importante comprender la diferencia entre desequilibrio relativo y  desequilibrio debido a casos raros (o "rareza absoluta") [20], [21]. Considere un conjunto de datos de mamografía con 100 000 ejemplos y un desequilibrio entre clases de 100:1. Esperaríamos que este conjunto de datos contuviera 1000 ejemplos de clases minoritarias; claramente, la clase mayoritaria domina a la clase minoritaria. Supongamos que luego duplicamos el espacio muestral probando a más pacientes, y supongamos además que la distribución no cambia, es decir, la clase minoritaria ahora contiene 2000 ejemplos. Claramente, la clase minoritaria todavía está superada en número; sin embargo, con 2000 ejemplos, la clase minoritaria no es necesariamente rara por derecho propio, sino más bien relativa a la clase mayoritaria. Este ejemplo es representativo de un desequilibrio relativo. Los desequilibrios relativos surgen con frecuencia en las aplicaciones del mundo real y, a menudo, son el foco de muchos esfuerzos de investigación de descubrimiento de conocimiento e ingeniería de datos. Algunos estudios han demostrado que para ciertos conjuntos de datos relativamente desequilibrados, el concepto de minoría se aprende con precisión con poca perturbación por el desequilibrio [22], [23], [24]. Estos resultados son particularmente sugerentes porque muestran que el grado de desequilibrio no es el único factor que dificulta el aprendizaje. Resulta que la complejidad del conjunto de datos es el principal factor determinante del deterioro de la clasificación, que, a su vez, se amplifica por la adición de un desequilibrio relativo. La complejidad de los datos es un término amplio que comprende problemas como la superposición, la falta de datos representativos, pequeñas disyunciones y otros. En un ejemplo simple, considere las distribuciones representadas en la figura 2. En esta figura, las estrellas y los círculos representan las clases mayoritaria y minoritaria, respectivamente. Por inspección, vemos que ambas distribuciones en las Figs. 2a y 2b muestran desequilibrios relativos. Sin embargo, observe cómo la Fig. 2a no tiene ejemplos superpuestos entre sus clases y solo tiene un concepto perteneciente a cada clase, mientras que la Fig. 2b tiene múltiples conceptos y superposición severa. También es de interés el subconcepto C en la distribución de la Fig. 2b. Este concepto puede pasar desapercibido por algunos inductores debido a la falta de datos representativos; este problema encarna desequilibrios debido a casos raros, que procedemos a explorar. El desequilibrio debido a casos raros es representativo de dominios donde los ejemplos de clases minoritarias son muy limitados, es decir, donde el concepto objetivo es raro. En esta situación, la falta de datos representativos dificultará el aprendizaje independientemente del desequilibrio entre clases [20]. Además, el concepto de minoría puede contener adicionalmente un subconcepto con instancias limitadas, lo que equivale a grados divergentes de dificultad de clasificación [25], [26]. Esto, de hecho, es el resultado de otra forma de desequilibrio, un desequilibrio dentro de la clase, que se relaciona con la distribución de datos representativos de los subconceptos dentro de una clase [27], [28], [29]. Estas ideas se destacan nuevamente en nuestro ejemplo simplificado en la Fig. 2. En la Fig. 2b, el grupo B representa el concepto de clase minoritaria dominante y el grupo C representa un subconcepto de la clase minoritaria. El grupo D representa dos subconceptos de la clase mayoritaria y el grupo A (todo lo que no está encerrado) representa el concepto de clase mayoritaria dominante. Para ambas clases, la cantidad de ejemplos en los grupos dominantes supera significativamente a los ejemplos en sus respectivos grupos de subconceptos, por lo que este espacio de datos exhibe desequilibrios tanto dentro de la clase como entre clases. Además, si eliminamos por completo los ejemplos en el grupo B, el espacio de datos tendría un concepto de clase minoritario homogéneo que se identifica fácilmente (grupo C), pero puede pasar desapercibido debido a su grave subrepresentación. La existencia de desequilibrios dentro de la clase está estrechamente relacionada con el problema de las pequeñas disyuntivas, que se ha demostrado que deprecian en gran medida el rendimiento de la clasificación [23], [27], [28], [29]. Brevemente, el problema de las disyuntivas pequeñas se puede entender de la siguiente manera: un clasificador intentará aprender un concepto creando múltiples reglas disyuntivas que describen el concepto principal [20], [25], [26]. En el caso de conceptos homogéneos, el clasificador generalmente creará grandes disyuntivas, es decir, reglas que cubren una gran parte (grupo) de ejemplos pertenecientes al concepto principal. Sin embargo, en el caso de conceptos heterogéneos, pequeñas disyunciones, es decir, reglas que cubren un pequeño grupo de ejemplos pertenecientes al concepto principal, surgen como resultado directo de subconceptos subrepresentados [20], [25], [26]. Además, dado que los clasificadores intentan aprender tanto los conceptos mayoritarios como los minoritarios, el problema de las pequeñas disyuntivas no se limita únicamente al concepto minoritario. Por el contrario, pequeñas disyunciones de la clase mayoritaria pueden surgir de ruidosos ejemplos de clases minoritarias mal clasificados o subconceptos subrepresentados. Sin embargo, debido a la gran representación de datos de clase mayoritaria, esta ocurrencia es poco frecuente. Un escenario más común es que el ruido pueda influir en las disyuntivas en la clase minoritaria. En este caso, la validez de los grupos correspondientes a las pequeñas disyuntivas se convierte en un tema importante, es decir, si estos ejemplos representan un subconcepto real o se atribuyen simplemente al ruido. Por ejemplo, en la Fig. 2b, supongamos que un clasificador genera disyunciones para cada una de las dos muestras minoritarias ruidosas en el grupo A, entonces estas serían disyunciones ilegítimas atribuidas al ruido en comparación con el grupo C, por ejemplo, que es un grupo legítimo formado a partir de un subconcepto severamente subrepresentado. El último problema que nos gustaría discutir es la combinación de datos desequilibrados y el problema del tamaño de muestra pequeño [30], [31]. En muchas de las aplicaciones actuales de análisis de datos y descubrimiento de conocimiento, a menudo es inevitable tener datos con una gran dimensionalidad y un tamaño de muestra pequeño; algunos ejemplos específicos incluyen reconocimiento facial y análisis de datos de expresión génica, entre otros. Tradicionalmente, el problema del tamaño de muestra pequeño se ha estudiado extensamente en la comunidad de reconocimiento de patrones [30]. Los métodos de reducción de la dimensionalidad se han adoptado ampliamente para manejar este problema, por ejemplo, el análisis de componentes principales (PCA) y varios métodos de extensión [32]. Sin embargo, cuando los conceptos de los conjuntos de datos representativos exhiben desequilibrios de las formas descritas anteriormente, la combinación de datos desequilibrados y tamaño de muestra pequeño presenta un nuevo desafío para la comunidad [31]. En esta situación, hay dos cuestiones críticas que surgen simultáneamente [31]. En primer lugar, dado que el tamaño de la muestra es pequeño, todos los problemas relacionados con la rareza absoluta y los desequilibrios dentro de la clase son aplicables. En segundo lugar y más importante, los algoritmos de aprendizaje a menudo no logran generalizar las reglas inductivas sobre el espacio muestral cuando se les presenta esta forma de desequilibrio. En este caso, la combinación de tamaño de muestra pequeño y alta dimensionalidad dificulta el aprendizaje debido a la dificultad que implica formar conjunciones sobre el alto grado de características con muestras limitadas. Si el espacio muestral es suficientemente grande, se puede definir un conjunto de reglas inductivas generales (aunque complejas) para el espacio de datos. Sin embargo, cuando las muestras son limitadas, las reglas formadas pueden volverse demasiado específicas, lo que lleva a un sobreajuste. En lo que respecta al aprendizaje de tales conjuntos de datos, este es un tema de investigación relativamente nuevo que requiere una atención muy necesaria en la comunidad. Como resultado, volveremos a tocar este tema más adelante en nuestras discusiones.

### 3 LAS SOLUCIONES DE VANGUARDIA PARA EL APRENDIZAJE DESEQUILIBRIO

Los temas discutidos en la Sección 2 proporcionan la base para la mayoría de las actividades de investigación actuales sobre el aprendizaje desequilibrado. En particular, los inmensos efectos obstaculizadores que estos problemas tienen sobre los algoritmos de aprendizaje estándar son el foco de la mayoría de las soluciones existentes. Cuando los algoritmos de aprendizaje estándar se aplican a datos desequilibrados, las reglas de inducción que describen los conceptos minoritarios suelen ser menos y más débiles que las de los conceptos mayoritarios, ya que la clase minoritaria suele ser superada en número y subrepresentada. Para proporcionar una comprensión concreta de los efectos directos del problema de aprendizaje desequilibrado en los algoritmos de aprendizaje estándar, observamos un estudio de caso del popular algoritmo de aprendizaje del árbol de decisiones. En este caso, los conjuntos de datos desequilibrados aprovechan las insuficiencias en el criterio de división en cada nodo del árbol de decisión [23], [24], [33]. Los árboles de decisión utilizan un algoritmo de búsqueda codicioso recursivo de arriba hacia abajo que utiliza un esquema de selección de características (por ejemplo, ganancia de información) para seleccionar la mejor característica como criterio de división en cada nodo del árbol; luego se crea un sucesor (hoja) para cada uno de los posibles valores correspondientes a la característica dividida [26], [34]. Como resultado, el conjunto de entrenamiento se divide sucesivamente en subconjuntos más pequeños que finalmente se usan para formar reglas inconexas relacionadas con los conceptos de clase. Estas reglas finalmente se combinan para que la hipótesis final minimice la tasa de error total en cada clase. El problema de este procedimiento en presencia de datos desequilibrados es doble. En primer lugar, la partición sucesiva del espacio de datos da como resultado cada vez menos observaciones de ejemplos de clases minoritarias, lo que da como resultado menos hojas que describen conceptos minoritarios y estimaciones de confianza cada vez más débiles. En segundo lugar, los conceptos que tienen dependencias en diferentes conjunciones de espacios de características pueden pasar desapercibidos por la escasez introducida a través de la partición. Aquí, el primer problema se correlaciona con los problemas de los desequilibrios relativos y absolutos, mientras que el segundo problema se correlaciona mejor con el desequilibrio entre clases y el problema de la alta dimensionalidad. En ambos casos, los efectos de los datos desequilibrados sobre el rendimiento de la clasificación del árbol de decisión son perjudiciales. En las siguientes secciones, evaluamos las soluciones propuestas para superar los efectos de los datos desequilibrados.

## 3.1.3 Muestreo sintético con generación de datos

En lo que respecta al muestreo sintético, la técnica de sobremuestreo de minorías sintéticas (SMOTE) es un método poderoso que ha demostrado un gran éxito en varias aplicaciones [13]. El algoritmo SMOTE crea datos artificiales basados en las similitudes del espacio de características entre los ejemplos minoritarios existentes. Específicamente, para el subconjunto $S_{min} \in S$, considere los K vecinos más cercanos para cada ejemplo $x_{i} \in S_{min}$, para algún entero K especificado; los K-vecinos más cercanos se definen como los K elementos de $ S_{min}$ cuya distancia euclidiana entre sí mismo y $ x_{i}$ bajo consideración exhibe la magnitud más pequeña a lo largo de las n-dimensiones del espacio de características X. Para crear una muestra sintética, seleccione aleatoriamente uno de los K-más cercanos vecinos, luego multiplique la diferencia del vector de características correspondiente con un número aleatorio entre [0, 1] y, finalmente, agregue este vector a $x_{i}$
$$x_{new}=x_{i}+(\^x-x_{i}) \hspace{1mm} x \hspace{1mm} \delta$$

[pag latex](http://elclubdelautodidacta.es/wp/2011/08/latex-capitulo-10-caracteres-prohibidos/)

[Lista Completa LAtex](https://manualdelatex.com/simbolos)

[SMOTE, Algoritmo para balanceo de clases en un
estudio aplicado a la ganadería.](http://sedici.unlp.edu.ar/bitstream/handle/10915/114339/Documento_completo.pdf-PDFA.pdf?sequence=1&isAllowed=y)

[Impacto de los algoritmos de sobremuestreo en la clasificación de subtipos principales del síndrome de guillain-barré](https://www.redalyc.org/journal/5055/505565143002/html/)

